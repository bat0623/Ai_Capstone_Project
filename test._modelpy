import torch
from cnn_model import CNNModel
from load_dataset import TextDataset
from konlpy.tag import Mecab

# 학습된 모델과 단어 사전 로드
data_dir = "C:/GitHub/Ai_Capstone_Project/data_set"  # 학습에 사용한 데이터셋 경로
seq_len = 20  # 학습 시 사용한 입력 시퀀스 길이

# 데이터셋을 다시 로드하여 단어 사전 획득 (단어->인덱스 및 인덱스->단어 매핑)
dataset = TextDataset(["테스트 문장입니다."], seq_len)
word2idx = dataset.word2idx
idx2word = dataset.idx2word
vocab_size = len(word2idx)

# 저장된 모델 가중치를 불러와 모델 초기화
model = CNNModel(vocab_size=vocab_size, seq_len=seq_len)
model.load_state_dict(torch.load("trained_model.pth", map_location=torch.device("cuda" if torch.cuda.is_available() else "cpu")))
model.eval()  # 평가 모드 전환 (dropout 비활성화 등)

# GPU 사용 여부 설정
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Mecab 형태소 분석기 초기화 (사용자 입력 텍스트를 형태소 단위로 변환)
mecab = Mecab()

def generate_text(seed_text, max_length=20):
    """사용자 입력 문장을 기반으로 이어지는 텍스트를 생성"""
    tokens = mecab.morphs(seed_text)  # 입력 문장을 형태소 단위로 토큰화
    result_text = seed_text  # 결과 문자열 초기값을 입력 문장으로 설정

    # 입력 시퀀스 길이를 학습 시 사용한 길이에 맞추기 (부족하면 PAD 토큰 추가)
    if len(tokens) < seq_len:
        tokens = ['<PAD>'] * (seq_len - len(tokens)) + tokens
    else:
        tokens = tokens[-seq_len:]  # 길이가 넘칠 경우 뒤쪽 단어를 유지

    # max_length 만큼 단어를 생성
    for _ in range(max_length):
        # 현재 토큰 시퀀스를 인덱스로 변환하여 모델에 입력
        idx_seq = [word2idx.get(token, word2idx['<UNK>']) for token in tokens]
        input_tensor = torch.tensor(idx_seq, dtype=torch.long).unsqueeze(0).to(device)  # (1, seq_len) 배치 형태 변환

        with torch.no_grad():
            output = model(input_tensor)  # 모델로부터 출력 얻기 (로짓 값)
            predicted_idx = output.argmax(dim=1).item()  # 가장 높은 확률의 단어 인덱스 선택

        predicted_word = idx2word.get(predicted_idx, '<UNK>')  # 인덱스를 단어로 변환

        # 예측된 단어를 결과에 추가 (띄어쓰기 처리: 문장부호는 바로 붙이고, 그 외는 띄어쓰기로 구분)
        if predicted_word in ['.', '!', '?', ',']:
            result_text += predicted_word
        else:
            result_text += ' ' + predicted_word

        # 새로운 단어를 토큰 리스트에 추가하고 시퀀스 업데이트
        tokens.append(predicted_word)
        tokens = tokens[-seq_len:]  # 최근 seq_len개의 토큰만 유지

        # 종료 조건: 예측 단어가 문장의 끝을 나타내는 경우 중단
        if predicted_word in ['.', '!', '?']:
            break

    return result_text

# 예제 실행: 해당 스크립트를 단독 실행할 때, 사용자 입력을 받아 문장을 생성
if __name__ == "__main__":
    input_sentence = input("시작 문장을 입력하세요: ")
    output_sentence = generate_text(input_sentence)
    print("생성된 문장:", output_sentence)
